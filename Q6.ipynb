{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Triansh/bert/blob/main/BERT_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZhFbfWgdeaW"
   },
   "source": [
    "## Libraries\n",
    "* Installing the transformers library \n",
    "* Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OqhcWmWWHc3e",
    "outputId": "2f6fd114-fedd-4033-edd0-385e9bca2e3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.12.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.1.2)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.2)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing<3,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wgAZowOAX2ON"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import gc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch import cuda\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ag11gfLnNys"
   },
   "outputs": [],
   "source": [
    "## Loading training and validation data for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "unIWFeGZKkVy"
   },
   "outputs": [],
   "source": [
    "def read_data(file_path):\n",
    "  return pd.read_csv(file_path, sep='\\t', header=None, names=['query', 'rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DakEQo-VYh6z",
    "outputId": "b567eb1c-666e-4fa4-cc9e-1f72a6bdec1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21250 entries, 0 to 21249\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   query   21250 non-null  object \n",
      " 1   rating  21250 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 332.2+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df =  read_data('./train.tsv')\n",
    "dev_df = read_data('./dev.tsv')\n",
    "train_df= train_df.append(dev_df).reset_index(drop=True)\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ECWmZ-EK70E",
    "outputId": "8dcd7148-22fd-4315-98f7-8642f3afd3d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3850 entries, 0 to 3849\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   query   3850 non-null   object \n",
      " 1   rating  3850 non-null   float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 60.3+ KB\n"
     ]
    }
   ],
   "source": [
    "validation_df = read_data('./test.tsv')\n",
    "validation_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QJmsnKBWkQlW"
   },
   "source": [
    "## Setting Random SEED and Devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "523sOIO26qkz"
   },
   "outputs": [],
   "source": [
    "SEED = 12345\n",
    "\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "rrKuXWsTZTBt",
    "outputId": "0f8290dc-ca2c-41ac-86d8-ff659a19f4f9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "# device = 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8RWiFUBYdBeJ"
   },
   "source": [
    "## Dataset and Dataloader instances\n",
    "* Creates a QWFDataset (Query well-formedness Dataset) inherited from the pytorch's dataset\n",
    "* Used pytorch's Dataloader to load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sejlNAoFZagM"
   },
   "outputs": [],
   "source": [
    "class QWFDataset(Dataset):\n",
    "  \n",
    "  def __init__(self, df, maxlen):\n",
    "    self.df = df.copy()\n",
    "    self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "    self.maxlen = maxlen\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.df)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    query = self.df['query'][index]\n",
    "    label = 1 if self.df['rating'][index] >= 0.8 else 0\n",
    "\n",
    "    encoded_dict = self.tokenizer.encode_plus(\n",
    "                        query,                        # Sentence to encode.\n",
    "                        add_special_tokens = True,    # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = self.maxlen,              # Pad & truncate all sentences.\n",
    "                        padding = 'max_length',\n",
    "                        truncation=True,\n",
    "                        return_attention_mask = True, # Construct attn. masks.\n",
    "                        return_tensors = 'pt',        # Return pytorch tensors.\n",
    "                    )\n",
    "    ids = encoded_dict['input_ids'].detach().clone().reshape((-1,))\n",
    "    mask = encoded_dict['attention_mask'].detach().clone().reshape((-1,))\n",
    "\n",
    "    # print(\"Shape of ids: \", ids.shape, mask.shape)\n",
    "\n",
    "    val = {\n",
    "        'ids': ids,\n",
    "        'mask': mask,\n",
    "        'targets': torch.tensor(label, dtype=torch.long)\n",
    "    } \n",
    "    # print(val)\n",
    "    return val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "57yG9_vbuFyv"
   },
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 32\n",
    "VALIDATION_BATCH_SIZE = 8\n",
    "MAX_LEN = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "go9_pYtILnIC"
   },
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 1\n",
    "                }\n",
    "\n",
    "validation_params = {'batch_size': VALIDATION_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 1\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e8zTIS_idzla",
    "outputId": "b073244e-6091-4aec-bd05-b2fa20d20519"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset: (21250, 2)\n",
      "VALIDATION Dataset: (3850, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Dataset: {train_df.shape}\")\n",
    "print(f\"VALIDATION Dataset: {validation_df.shape}\")\n",
    "\n",
    "train_set =  QWFDataset(train_df, maxlen=MAX_LEN)\n",
    "validation_set =  QWFDataset(validation_df, maxlen=MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_MsnAGwcLhVS"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, **train_params)\n",
    "validation_loader = DataLoader(validation_set, **validation_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sjKjDaj0l_S8"
   },
   "source": [
    "## Fine-tuning the pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SlDDkOouL5dO"
   },
   "outputs": [],
   "source": [
    "class QWFClassificationModel(nn.Module):\n",
    "\n",
    "  def __init__(self ):\n",
    "    super(QWFClassificationModel, self).__init__()\n",
    "\n",
    "    self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "    self.pre_classifier = nn.Linear(768, 512)\n",
    "    self.relu = nn.ReLU()\n",
    "    self.dropout = nn.Dropout(0.3)\n",
    "    self.classifier = nn.Linear(512, 1)\n",
    "\n",
    "  def forward(self, tokens, attention_mask):\n",
    "    hidden_state, _ = self.bert(tokens, attention_mask = attention_mask,return_dict=False)\n",
    "    pooler = hidden_state[:, 0]\n",
    "    pooler = self.pre_classifier(pooler)\n",
    "    pooler = self.relu(pooler)\n",
    "    pooler = self.dropout(pooler)\n",
    "    outputs = self.classifier(pooler)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4dWKNdKvckr_"
   },
   "outputs": [],
   "source": [
    "def get_correct(outputs, targets):\n",
    "  # print(outputs)\n",
    "  probs = torch.sigmoid(outputs)\n",
    "  # print('prob from train: ',probs)\n",
    "  labels = (probs >= 0.5).long()\n",
    "  n_correct = (labels==targets).sum().item()\n",
    "  return n_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b6QK9dV5s5Cq"
   },
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xr5FNBTtXKvx",
    "outputId": "de1a3b87-ca01-49a0-c6ff-ecd1f8237026"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = QWFClassificationModel()\n",
    "x = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "llPVg05XXPv1"
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-5\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(params = model.parameters(), lr = learning_rate)\n",
    "epochs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "itqI0hhUmHhz"
   },
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KMmd77haX3Gz"
   },
   "outputs": [],
   "source": [
    "def train(epoch, data_loader):\n",
    "\n",
    "  training_loss = 0\n",
    "  training_count = 0\n",
    "  total_correct = 0\n",
    "\n",
    "  model.train()\n",
    "\n",
    "  loop = tqdm(data_loader,leave=True)\n",
    "\n",
    "  for batch in loop:\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    ids = batch['ids'].to(device, dtype = torch.long)\n",
    "    mask = batch['mask'].to(device, dtype = torch.long)\n",
    "    targets = batch['targets'].to(device, dtype = torch.long)\n",
    "\n",
    "    outputs = model(ids, mask).squeeze()\n",
    "    loss = criterion(outputs, targets.float())\n",
    "\n",
    "    training_loss += loss.item()\n",
    "    total_correct += get_correct(outputs.data, targets)\n",
    "    training_count+=targets.size(0)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    loop.set_description(f'Epoch {epoch}')\n",
    "    loop.set_postfix(loss=loss.item())\n",
    "\n",
    "  epoch_loss = training_loss / len(data_loader)\n",
    "  epoch_accu = total_correct * 100 / training_count\n",
    "  print(f\"The Mean loss for Epoch: {epoch_loss}\")\n",
    "  print(f\"The Total Accuracy for Epoch {epoch}: {epoch_accu}\")\n",
    "\n",
    "  return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "drxPGxt8YNhX",
    "outputId": "23c930c7-123d-414a-dcbd-ebe5fc095a59"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 665/665 [04:23<00:00,  2.53it/s, loss=1.14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mean loss for Epoch: 0.4594027056953961\n",
      "The Total Accuracy for Epoch 0: 77.41176470588235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 665/665 [04:22<00:00,  2.53it/s, loss=0.24]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mean loss for Epoch: 0.3388124349422025\n",
      "The Total Accuracy for Epoch 1: 85.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "  train(epoch, train_loader)\n",
    "# model.save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gMW_vdyQmKOC"
   },
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RHGmQg3GwH5-"
   },
   "outputs": [],
   "source": [
    "def validate(model, validation_loader):\n",
    "  model.eval()\n",
    "\n",
    "  validation_loss = 0\n",
    "  validation_count = 0\n",
    "  total_correct = 0\n",
    "\n",
    "  with torch.no_grad():\n",
    "    loop = tqdm(validation_loader,leave=True)\n",
    "\n",
    "    for data in loop:\n",
    "\n",
    "      ids = data['ids'].to(device, dtype = torch.long)\n",
    "      mask = data['mask'].to(device, dtype = torch.long)\n",
    "      targets = data['targets'].to(device, dtype = torch.long)\n",
    "\n",
    "      outputs = model(ids, mask).squeeze()\n",
    "\n",
    "      loss = criterion(outputs, targets.float())\n",
    "      validation_loss += loss.item()\n",
    "\n",
    "      total_correct += get_correct(outputs.data, targets)\n",
    "\n",
    "      validation_count += targets.size(0)\n",
    "\n",
    "    accuarcy = total_correct * 100 / validation_count\n",
    "    print(f\"Validation Loss : {validation_loss / len(validation_loader)}\")\n",
    "    print(f\"Validation Accuracy : {accuarcy}\")\n",
    "    return accuarcy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "htIYmiqndPav",
    "outputId": "f848caab-52de-496f-c4b0-c9690b7d1516"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 482/482 [00:22<00:00, 21.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss : 0.39552819328884986\n",
      "Validation Accuracy : 82.44155844155844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = validate(model, validation_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bBcpLcirzTyt"
   },
   "outputs": [],
   "source": [
    "torch.save(model, f'./model-{str(accuracy)}-{SEED}')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "BERT Assignment",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
