{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT Assignment",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP33tXXjmdGxNRIX/knCMxh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Triansh/bert/blob/main/BERT_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZhFbfWgdeaW"
      },
      "source": [
        "## Libraries\n",
        "* Installing the transformers library \n",
        "* Importing the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqhcWmWWHc3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f02167df-0119-4e04-f3fe-0b5bec22c248"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.12.3-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 5.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.2)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 32.9 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.1.2-py3-none-any.whl (59 kB)\n",
            "\u001b[K     |████████████████████████████████| 59 kB 6.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 50.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.2)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 42.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing<3,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.1.2 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.12.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgAZowOAX2ON"
      },
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import gc\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch import cuda\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ag11gfLnNys"
      },
      "source": [
        "## Loading training and validation data for fine-tuning"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unIWFeGZKkVy"
      },
      "source": [
        "def read_data(file_path):\n",
        "  return pd.read_csv(file_path, sep='\\t', header=None, names=['query', 'rating'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DakEQo-VYh6z",
        "outputId": "5d321a76-217a-480f-920a-884785472482"
      },
      "source": [
        "train_df =  read_data('./train.tsv')\n",
        "dev_df = read_data('./dev.tsv')\n",
        "train_df= train_df.append(dev_df).reset_index(drop=True)\n",
        "train_df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 21250 entries, 0 to 21249\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   query   21250 non-null  object \n",
            " 1   rating  21250 non-null  float64\n",
            "dtypes: float64(1), object(1)\n",
            "memory usage: 332.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ECWmZ-EK70E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95787b93-1a14-4444-a632-afc65afc9517"
      },
      "source": [
        "validation_df = read_data('./test.tsv')\n",
        "validation_df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3850 entries, 0 to 3849\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   query   3850 non-null   object \n",
            " 1   rating  3850 non-null   float64\n",
            "dtypes: float64(1), object(1)\n",
            "memory usage: 60.3+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJmsnKBWkQlW"
      },
      "source": [
        "## Setting Random SEED and Devices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "523sOIO26qkz"
      },
      "source": [
        "SEED = 12345\n",
        "\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.use_deterministic_algorithms(True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "rrKuXWsTZTBt",
        "outputId": "39d3da3f-b968-4991-a507-ecdfb32761c1"
      },
      "source": [
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "# device = 'cpu'\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda'"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RWiFUBYdBeJ"
      },
      "source": [
        "## Dataset and Dataloader instances\n",
        "* Creates a QWFDataset (Query well-formedness Dataset) inherited from the pytorch's dataset\n",
        "* Used pytorch's Dataloader to load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sejlNAoFZagM"
      },
      "source": [
        "class QWFDataset(Dataset):\n",
        "  \n",
        "  def __init__(self, df, maxlen):\n",
        "    self.df = df.copy()\n",
        "    self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "    self.maxlen = maxlen\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.df)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    query = self.df['query'][index]\n",
        "    label = 1 if self.df['rating'][index] >= 0.8 else 0\n",
        "\n",
        "    encoded_dict = self.tokenizer.encode_plus(\n",
        "                        query,                        # Sentence to encode.\n",
        "                        add_special_tokens = True,    # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = self.maxlen,              # Pad & truncate all sentences.\n",
        "                        padding = 'max_length',\n",
        "                        truncation=True,\n",
        "                        return_attention_mask = True, # Construct attn. masks.\n",
        "                        return_tensors = 'pt',        # Return pytorch tensors.\n",
        "                    )\n",
        "    ids = encoded_dict['input_ids'].detach().clone().reshape((-1,))\n",
        "    mask = encoded_dict['attention_mask'].detach().clone().reshape((-1,))\n",
        "\n",
        "    # print(\"Shape of ids: \", ids.shape, mask.shape)\n",
        "\n",
        "    val = {\n",
        "        'ids': ids\n",
        "        'mask': mask\n",
        "        'targets': torch.tensor(label, dtype=torch.long)\n",
        "    } \n",
        "    # print(val)\n",
        "    return val\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57yG9_vbuFyv"
      },
      "source": [
        "TRAIN_BATCH_SIZE = 32\n",
        "VALIDATION_BATCH_SIZE = 8\n",
        "MAX_LEN = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "go9_pYtILnIC"
      },
      "source": [
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 1\n",
        "                }\n",
        "\n",
        "validation_params = {'batch_size': VALIDATION_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 1\n",
        "                }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8zTIS_idzla",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3c0219a-2bcf-4e60-d781-648dfce90a0c"
      },
      "source": [
        "print(f\"Training Dataset: {train_df.shape}\")\n",
        "print(f\"VALIDATION Dataset: {validation_df.shape}\")\n",
        "\n",
        "train_set =  QWFDataset(train_df, maxlen=MAX_LEN)\n",
        "validation_set =  QWFDataset(validation_df, maxlen=MAX_LEN)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Dataset: (21250, 2)\n",
            "VALIDATION Dataset: (3850, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MsnAGwcLhVS"
      },
      "source": [
        "train_loader = DataLoader(train_set, **train_params)\n",
        "validation_loader = DataLoader(validation_set, **validation_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjKjDaj0l_S8"
      },
      "source": [
        "## Fine-tuning the pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlDDkOouL5dO"
      },
      "source": [
        "class QWFClassificationModel(nn.Module):\n",
        "\n",
        "  def __init__(self ):\n",
        "    super(QWFClassificationModel, self).__init__()\n",
        "\n",
        "    self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "    self.pre_classifier = nn.Linear(768, 512)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.dropout = nn.Dropout(0.1)\n",
        "    self.classifier = nn.Linear(512, 1)\n",
        "\n",
        "  def forward(self, tokens, attention_mask):\n",
        "    hidden_state, _ = self.bert(tokens, attention_mask = attention_mask,return_dict=False)\n",
        "    pooler = hidden_state[:, 0]\n",
        "    pooler = self.pre_classifier(pooler)\n",
        "    pooler = self.relu(pooler)\n",
        "    pooler = self.dropout(pooler)\n",
        "    outputs = self.classifier(pooler)\n",
        "    return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dWKNdKvckr_"
      },
      "source": [
        "def get_correct(outputs, targets):\n",
        "  # print(outputs)\n",
        "  probs = torch.sigmoid(outputs)\n",
        "  # print('prob from train: ',probs)\n",
        "  labels = (probs >= 0.5).long()\n",
        "  n_correct = (labels==targets).sum().item()\n",
        "  return n_correct"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6QK9dV5s5Cq"
      },
      "source": [
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xr5FNBTtXKvx",
        "outputId": "72d10242-8e5a-4807-9bd4-174e133b8f6a"
      },
      "source": [
        "model = QWFClassificationModel()\n",
        "x = model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llPVg05XXPv1"
      },
      "source": [
        "learning_rate = 1e-5\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(params = model.parameters(), lr = learning_rate)\n",
        "epochs = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itqI0hhUmHhz"
      },
      "source": [
        "## Training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMmd77haX3Gz"
      },
      "source": [
        "def train(epoch, data_loader):\n",
        "\n",
        "  training_loss = 0\n",
        "  training_count = 0\n",
        "  total_correct = 0\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  loop = tqdm(data_loader,leave=True)\n",
        "\n",
        "  for batch in loop:\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    ids = batch['ids'].to(device, dtype = torch.long)\n",
        "    mask = batch['mask'].to(device, dtype = torch.long)\n",
        "    targets = batch['targets'].to(device, dtype = torch.long)\n",
        "\n",
        "    outputs = model(ids, mask).squeeze()\n",
        "    loss = criterion(outputs, targets.float())\n",
        "\n",
        "    training_loss += loss.item()\n",
        "    total_correct += get_correct(outputs.data, targets)\n",
        "    training_count+=targets.size(0)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    loop.set_description(f'Epoch {epoch}')\n",
        "    loop.set_postfix(loss=loss.item())\n",
        "\n",
        "  epoch_loss = training_loss / len(data_loader)\n",
        "  epoch_accu = total_correct * 100 / training_count\n",
        "  print(f\"The Mean loss for Epoch: {epoch_loss}\")\n",
        "  print(f\"The Total Accuracy for Epoch {epoch}: {epoch_accu}\")\n",
        "\n",
        "  return "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "drxPGxt8YNhX",
        "outputId": "ec434e6e-cf78-4fa6-bde4-fd9d5a7ce43b"
      },
      "source": [
        "for epoch in range(epochs):\n",
        "  train(epoch, train_loader)\n",
        "# model.save"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/665 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "100%|██████████| 665/665 [07:33<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-df8972877d32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# model.save\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-a0c3738c2af7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, data_loader)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m   \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m   \u001b[0mepoch_accu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_correct\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtraining_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"The Mean loss for Epoch: {epoch_loss}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"The Total Accuracy for Epoch {epoch}: {epoch_accu}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'n_correct' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMW_vdyQmKOC"
      },
      "source": [
        "## Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHGmQg3GwH5-"
      },
      "source": [
        "def validate(model, validation_loader):\n",
        "  model.eval()\n",
        "\n",
        "  validation_loss = 0\n",
        "  validation_count = 0\n",
        "  total_correct = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    loop = tqdm(data_loader,leave=True)\n",
        "\n",
        "    for batch in loop:\n",
        "\n",
        "      ids = data['ids'].to(device, dtype = torch.long)\n",
        "      mask = data['mask'].to(device, dtype = torch.long)\n",
        "      targets = data['targets'].to(device, dtype = torch.long)\n",
        "\n",
        "      outputs = model(ids, mask).squeeze()\n",
        "\n",
        "      loss = criterion(outputs, targets.float())\n",
        "      validation_loss += loss.item()\n",
        "\n",
        "      total_correct += get_correct(outputs.data, targets)\n",
        "\n",
        "      validation_count += targets.size(0)\n",
        "\n",
        "    print(f\"Validation Loss : {validation_loss / len(data_loader)}\")\n",
        "    print(f\"Validation Accuracy : {total_correct * 100 / validation_count}\")\n",
        "    return epoch_accu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htIYmiqndPav",
        "outputId": "de15f5be-e46f-447f-c519-d6e00e375793"
      },
      "source": [
        "accuracy = validate(model, validation_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss per 100 steps: 0.45467622943222524\n",
            "Validation Accuracy per 100 steps: 79.125\n",
            "Validation Loss per 100 steps: 0.4443891962431371\n",
            "Validation Accuracy per 100 steps: 79.8125\n",
            "Validation Loss per 100 steps: 0.451128485960265\n",
            "Validation Accuracy per 100 steps: 79.375\n",
            "Validation Loss per 100 steps: 0.44184628397226333\n",
            "Validation Accuracy per 100 steps: 79.96875\n",
            "Validation Loss Epoch: 0.4397104711198349\n",
            "Validation Accuracy Epoch: 80.05333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBcpLcirzTyt"
      },
      "source": [
        "torch.save(model, f'./model-{str(accuracy)}-{SEED}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5CVhYX66ntx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}